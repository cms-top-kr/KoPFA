[CRAB]
#
#   This section contains the default values for general parameters.
#   They can be set also as a command-line option, i.e.
#
#   key1 = value1
#   [SECTION]
#   key2 = value2
#
#   in this section corresponds to
#
#   crab.py -key1=value1 -key2=SECTION.value2
#
#   in the command line.
#
jobtype = cmssw

### Specify the scheduler to be used.
### Supported schedulers are : [ edg, glite, condor_g]
scheduler = glite

### To configure CRAB  as client set the name of the server
### (e.g. pi, lnl etc etc )
### CRAB will submit jobs to the server, which will submit and manage for the users
#server_name = cnaf

use_server = 1

[CMSSW]

### The data you want to access (to be found on DBS)
### /primarydataset/processeddataset/datatier[/OptionalADS]
#datasetpath=/ttbar_inclusive_TopRex/CMSSW_1_3_1-Spring07-1122/GEN-SIM-DIGI-RECO

### Within a dataset you can ask to run over the related parent files too.
### E.g., this will give you access to the RAW data while running over a RECO sample.
### Setting use_parent=True CRAB determines the parent files from DBS and will add
### secondaryFileNames = cms.untracked.vstring( <LIST of parent FIles> ) to the pool source section of your parameter set.
#use_parent = True

### To run CRAB for private events production set datasetPath= None
## runs 131511-135802
#datasetpath=/MinimumBias/Commissioning10-May27thSkim_SD_Mu-v2/RECO 
## runs 135821-136587
#datasetpath=/Mu/Run2010A-May27thReReco_v2/RECO
## runs 136588-999999
#datasetpath=/Mu/Run2010A-PromptReco-v2/RECO 

### To select a single (list of) run within a single processed dataset define run number (list)
### selection can be a comma-separated list of run numbers and run number ranges: 1,2,3-4
#runselection=1,2,3-4


### Specifies a comma separated list of seeds to increment from job to job. The initial value is taken from the CMSSW config file.
### increment_seeds=sourceSeed,g4SimHits will set sourceSeed=11,12,13 and g4SimHits=21,22,23 on subsequent jobs if the values of
### the two seeds are 10 and 20 in the CMSSW config file.
### See also preserve_seeds. Seeds not listed in increment_seeds or preserve_seeds are randomly set for each job.
#increment_seeds=sourceSeed,g4SimHits

### Specifies a comma separated list of seeds to which CRAB will not change from their values in the user CMSSW config file.
### preserve_seeds=sourceSeed,g4SimHits will leave the Pythia and GEANT seeds the same for every job.
### See also increment_seeds. Seeds not listed in increment_seeds or preserve_seeds are randomly set for each job.
#preserve_seeds=sourceSeed,g4SimHits

### First run to be generated in a generation jobs. Relevant only for no-input workflow.
#first_run=3

### Name of the generator your MC job is using. Some generators require CRAB to skip events, others do not.
### Possible values are pythia (default), comphep, lhe, and madgraph. This will skip events in your generator input file.
#generator=pythia

### Force CRAB to skip the inclusion of file produced by TFileService to list of output files.
### Default is 0, namely the file is included.
# skip_TFileService_output = 1

### Force CRAB to add the EDM output file, as defined in PSET in PoolOutputModule (if any)
### to be added to the list of output files. Default is 0 (== no inclusion)
# get_edm_output = 1


### To use a local DBS istance specify the related URL here.
# dbs_url = http://cmsdoc.cern.ch/cms/test/aprom/DBS/CGIServer/prodquery

### The name of ParameterSet to be used
pset=pf2pat_vallot_cfg.py
#pset=SDMuon_cfg.py
#pset=makeTauNtuple_Simone_cfg.py

### Splitting parameters:
### Total number of events to be accessed: -1 means all
### NOTE: "-1" is not usable if no input
#total_number_of_events=1000

### Number of events to be processed per job
events_per_job = 5000

### Number of jobs to be created per task
#number_of_jobs = 5

### Analogous to events, lumis are used to split up analysis datasets

#lumis_per_job = 1

#lumi_mask=Run131511_135802_JSON.json
#lumi_mask=Run135821_136587_JSON.json
#lumi_mask=Run136588_999999_JSON.json

#total_number_of_lumis = -1

### The output files produced by your application (comma separated list)
output_file = PF2PAT_SDMUON_GOODCOLL_MuonFilter.root, PF2PAT_SDMUON_GOODCOLL_PFMuonFilter.root, vallot.root
#output_file = test.root
### Dataset of PU to import in the local DBS for data publication
#dataset_pu = /pileup/dataset/toimport

[USER]

### If CRAB.server_mode = 1
### To set Your e-mail address to be used by the server to notify you
#eMail = your_email_address

### If CRAB.server_mode = 1
### To specify the percentage of finished job in a task, corresponding
### to when the notification email will be sent to you by the server default is 100%
#thresholdLevel = 100

### To use a specific name of UI directory where CRAB will create job to submit (with full path).
### the default directory will be "crab_0_data_time"
#ui_working_dir = /full/path/Name_of_Directory

### OUTPUT file management ###
### To have back the job executable output into UI set return_data= 1
return_data = 0

### To specify the UI directory where to store the CMS executable output
### FULL path is mandatory. Default is  <ui_working_dir>/res will be used.
#outputdir= /tmp/tjkim

### To specify the UI directory where to store the stderr, stdout and .BrokerInfo of submitted jobs
### FULL path is mandatory. Default is <ui_working_dir>/res will be used.
#logdir= /tmp/tjkim


### To copy the CMS executable output into a SE set copy_data = 1
copy_data = 1

### if you want to copy data in a "official CMS site"
### you have to specify the name as written in
#storage_element = T2_IT_Bari
### the user_remote_dir will be created under the SE mountpoint
### in the case of publication this directory is not considered
#user_remote_dir = name_directory_you_want

### if you want to copy your data at CAF
#storage_element = T2_CH_CAF
### the user_remote_dir will be created under the SE mountpoint
### in the case of publication this directory is not considered
#user_remote_dir = name_directory_you_want

### if you want to copy your data to your area in castor at cern
### or in a "not official CMS site" you have to specify the complete name of SE
storage_element=srm-cms.cern.ch
### this directory is the mountpoin of SE
storage_path=/srm/managerv2?SFN=/castor/cern.ch/
### directory or tree of directory under the mounpoint
#user_remote_dir=user/t/tjkim/SDMUONFILTER/CMSSW_361p2_v4

### if you are using CAF scheduler, you can specify the pool
### where to write your output. The default is cmscafuser
#storage_pool = cmscafuser

### This is the storage port number. Default is 8443
#storage_port = N

### To specify the version of srm client to use. Should match managerv[x] above.
### it can be srmv1 or srmv2
#srm_version = srmv2

### To use the local stage out (local to the closeSE) in case of remote stage out failure.
### The publication of data is not supported with local_stage_out = 1. Work in progress
local_stage_out= 0

### To publish produced output in a local istance of DBS set publish_data = 1
publish_data=0
### To publish your data importing in your local DBS the complete parents three, set publish_with_import_all_parents=1
publish_with_import_all_parents=0
### Specify the dataset name. The full path will be <primarydataset>/<publish_data_name>/USER
#publish_data_name = yourDataName
### Specify the URL of DBS istance where CRAB has to publish the output files
#dbs_url_for_publication = http://cmssrv17.fnal.gov:8989/DBS108LOC1/servlet/DBSServlet


### To specify additional files to be put in InputSandBox
### write the full path  if the files are not in the current directory
### (wildcard * are allowed): comma separated list
#additional_input_files = file1, file2, /full/path/file3

### A user script that will be run on WN (instead of default cmsrun). It is up to the user to setup properly the script itself to
### run on WN enviroment. CRAB guarantees that the CMSSW environment is setup (e.g. scram is in the path) and that the modified
### pset.cfg will be placed in the working directory, with name CMSSW.cfg . The user must ensure that a job report named
### crab_fjr.xml will be written. This can be guaranteed by passing the arguments "-j crab_fjr.xml" to cmsRun in the script. The
### script itself will be added automatically to the input sandbox so user MUST NOT add it within the USER.additional_input_files.
#script_exe=file_exe

### To switch from status print on screen to DB serialization to a file specify here the destination files.
### CRAB will create it on CRAB_Working_Dir/share
#xml_report=name_you_want

### To use the automate namespace definition (perfomed by CRAB). Default is 0
### The same policy used for the stage out in case of data publication will be applied.
#usenamespace=1

### To enable the higer verbose level on wrapper specify debug_wrapper = True.
### The Pset contents before and after the CRAB manipulation will be written
### together with other useful infos.
#debug_wrapper = True

### Set it to 1 to skip the check of free space left on your working directory
### before attempting to get the output back. Default is 0 (=False)
#dontCheckSpaceLeft = 1


[GRID]

### To change the CMS-broker RB/WMS to be used. The ones available for CMS
### are "CERN" and "CNAF": the configuration
### files needed to change the broker will be automatically downloaded from CRAB web page.
### If the files are already present on the working directory they will be used.
#rb = CNAF

### CMS myproxy server, to proxy delegation
proxy_server = myproxy.cern.ch

### To specify  VOMS role and/or group
#role = superman
#group = superheros

### To skip the CRAB check of your proxy
#dont_check_proxy = 1

### To add other requirements to jdl file, as example the Operating System
#requirements = (other.GlueHostOperatingSystemName == "RedHat")

### To add other parameters to jdl file: semicolon separated list;
#additional_jdl_parameters = AllowZippedISB = false

### To use a specific WMS end point put here the right name:
#wms_service=

### To specify a cpu time and wall_clock_time(=real time) in minutes
#max_cpu_time = 60
#max_wall_clock_time = 60

### To manage White/Black lists: For discovery, please use http://cmslcgco01.cern.ch:8001/
### Use the dns domain (eg fnal, cern, ifae, fzk, cnaf, lnl,....) or the CMSSite name
### T1_US_FNAL. Only Tier2 centers have resources dedicated to user analysis.
### All the storage/computing elements (SE/CE) contained in the strings (comma separated list)
### will/will not be considered for submission.
### SE Black List:
se_black_list = T0,T1,T2_FR_GRIF_IRFU
### SE White List
#se_white_list = T2_CH_CSCS

### CE Black List:
ce_black_list = T2_US_Wisconsin,T2_US_Nebraska,T2_TW_Taiwan,T2_US_Caltech,T2_US_UCSD,T2_US_Florida,T2_ES_IFCA
### CE White List:
#ce_white_list = infn

## fields written into jdl
virtual_organization = cms

### Temporary useful parameter to allow the WMSAuthorisation handling. Specifying skipwmsauth = 1
### the pyopenssl problems will disappear. It is needed working on gLite UI outside of CERN.
#skipwmsauth=1


[CONDORG]

# Set this to condor to override the batchsystem defined in gridcat.
#batchsystem = condor

# Specify addition condor_g requirments
# use this requirment to run on a cms dedicated hardare
# globus_rsl = (condor_submit=(requirements 'ClusterName == \"CMS\" && (Arch == \"INTEL\" || Arch == \"X86_64\")'))
# use this requirement to run on the new hardware
#globus_rsl = (condor_submit=(requirements 'regexp(\"cms-*\",Machine)'))


